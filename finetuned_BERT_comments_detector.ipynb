{
 "cells": [
  {
   "cell_type": "code",
   "id": "e93c64c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:54.960973Z",
     "start_time": "2025-04-17T15:36:52.352590Z"
    }
   },
   "source": [
    "!pip install openpyxl"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "a40d8f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.119975Z",
     "start_time": "2025-04-17T15:36:54.987986Z"
    }
   },
   "source": [
    "!pip install --upgrade jupyter ipywidgets"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.1.6)\n",
      "Requirement already satisfied: notebook in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter) (7.3.2)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter) (4.3.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: decorator in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (1.8.12)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel->jupyter) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (0.27.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from jupyterlab->jupyter) (8.6.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (3.1.3)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (58.1.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (4.13.3)\n",
      "Requirement already satisfied: bleach[css]!=5.0.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (3.1.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.8.3->jupyterlab->jupyter) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (308)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\huisu\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.22.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.2.0)\n",
      "Requirement already satisfied: fqdn in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.9.0.20241206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\huisu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "da534d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.182735Z",
     "start_time": "2025-04-17T15:36:58.168713Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import csv"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "d3f06d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.400341Z",
     "start_time": "2025-04-17T15:36:58.231422Z"
    }
   },
   "source": [
    "csv_file = '1500data.xlsx'\n",
    "df = pd.read_excel(csv_file)\n",
    "#df = pd.read_csv(csv_file)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     sl                           Project  pullNumber         author  \\\n",
       "0  9320     nightscout/cgm-remote-monitor        6288     jpcunningh   \n",
       "1  9321                      apache/spark       43881  dongjoon-hyun   \n",
       "2  9322                      apache/spark       43881  dongjoon-hyun   \n",
       "3  9323                      apache/spark       43881    LuciferYang   \n",
       "4  9324  spring-projects/spring-framework       29816        bclozel   \n",
       "\n",
       "                                             comment                  path  \\\n",
       "0  Commenter: jpcunningh\\nCreated At: 2020-11-04T...                   NaN   \n",
       "1  Commenter: dongjoon-hyun\\nCreated At: 2023-11-...  dev/infra/Dockerfile   \n",
       "2  Commenter: dongjoon-hyun\\nCreated At: 2023-11-...                   NaN   \n",
       "3  Commenter: LuciferYang\\nCreated At: 2023-11-20...                   NaN   \n",
       "4  Commenter: bclozel\\nCreated At: 2023-01-13T17:...                   NaN   \n",
       "\n",
       "   Unnamed: 6                                                URL  label  \n",
       "0         NaN  https://github.com/nightscout/cgm-remote-monit...      1  \n",
       "1         NaN  https://github.com/apache/spark/pull/43881#dis...      1  \n",
       "2         NaN  https://github.com/apache/spark/pull/43881#iss...      1  \n",
       "3         NaN  https://github.com/apache/spark/pull/43881#iss...      1  \n",
       "4         NaN  https://github.com/spring-projects/spring-fram...      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>URL</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9320</td>\n",
       "      <td>nightscout/cgm-remote-monitor</td>\n",
       "      <td>6288</td>\n",
       "      <td>jpcunningh</td>\n",
       "      <td>Commenter: jpcunningh\\nCreated At: 2020-11-04T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/nightscout/cgm-remote-monit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9321</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>dongjoon-hyun</td>\n",
       "      <td>Commenter: dongjoon-hyun\\nCreated At: 2023-11-...</td>\n",
       "      <td>dev/infra/Dockerfile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9322</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>dongjoon-hyun</td>\n",
       "      <td>Commenter: dongjoon-hyun\\nCreated At: 2023-11-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#iss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9323</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>LuciferYang</td>\n",
       "      <td>Commenter: LuciferYang\\nCreated At: 2023-11-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#iss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9324</td>\n",
       "      <td>spring-projects/spring-framework</td>\n",
       "      <td>29816</td>\n",
       "      <td>bclozel</td>\n",
       "      <td>Commenter: bclozel\\nCreated At: 2023-01-13T17:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/spring-projects/spring-fram...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "fa60f761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.510685Z",
     "start_time": "2025-04-17T15:36:58.496235Z"
    }
   },
   "source": [
    "df.label.value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1245\n",
       "0     358\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "a2b3ace9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.618258Z",
     "start_time": "2025-04-17T15:36:58.604815Z"
    }
   },
   "source": [
    "possible_labels = df.label.unique()\n",
    "possible_labels"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "9464e782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.805290Z",
     "start_time": "2025-04-17T15:36:58.788588Z"
    }
   },
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "90d792c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:58.960253Z",
     "start_time": "2025-04-17T15:36:58.947228Z"
    }
   },
   "source": [
    "label_dict = {'1': 1, '0': 0}\n",
    "label_dict"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, '0': 0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "cad10c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.008382Z",
     "start_time": "2025-04-17T15:36:58.995346Z"
    }
   },
   "source": [
    "df['label'] = df.label.replace(label_dict)"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "4d347c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.086250Z",
     "start_time": "2025-04-17T15:36:59.072726Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     sl                           Project  pullNumber         author  \\\n",
       "0  9320     nightscout/cgm-remote-monitor        6288     jpcunningh   \n",
       "1  9321                      apache/spark       43881  dongjoon-hyun   \n",
       "2  9322                      apache/spark       43881  dongjoon-hyun   \n",
       "3  9323                      apache/spark       43881    LuciferYang   \n",
       "4  9324  spring-projects/spring-framework       29816        bclozel   \n",
       "\n",
       "                                             comment                  path  \\\n",
       "0  Commenter: jpcunningh\\nCreated At: 2020-11-04T...                   NaN   \n",
       "1  Commenter: dongjoon-hyun\\nCreated At: 2023-11-...  dev/infra/Dockerfile   \n",
       "2  Commenter: dongjoon-hyun\\nCreated At: 2023-11-...                   NaN   \n",
       "3  Commenter: LuciferYang\\nCreated At: 2023-11-20...                   NaN   \n",
       "4  Commenter: bclozel\\nCreated At: 2023-01-13T17:...                   NaN   \n",
       "\n",
       "   Unnamed: 6                                                URL  label  \n",
       "0         NaN  https://github.com/nightscout/cgm-remote-monit...      1  \n",
       "1         NaN  https://github.com/apache/spark/pull/43881#dis...      1  \n",
       "2         NaN  https://github.com/apache/spark/pull/43881#iss...      1  \n",
       "3         NaN  https://github.com/apache/spark/pull/43881#iss...      1  \n",
       "4         NaN  https://github.com/spring-projects/spring-fram...      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>URL</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9320</td>\n",
       "      <td>nightscout/cgm-remote-monitor</td>\n",
       "      <td>6288</td>\n",
       "      <td>jpcunningh</td>\n",
       "      <td>Commenter: jpcunningh\\nCreated At: 2020-11-04T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/nightscout/cgm-remote-monit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9321</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>dongjoon-hyun</td>\n",
       "      <td>Commenter: dongjoon-hyun\\nCreated At: 2023-11-...</td>\n",
       "      <td>dev/infra/Dockerfile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9322</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>dongjoon-hyun</td>\n",
       "      <td>Commenter: dongjoon-hyun\\nCreated At: 2023-11-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#iss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9323</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>LuciferYang</td>\n",
       "      <td>Commenter: LuciferYang\\nCreated At: 2023-11-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#iss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9324</td>\n",
       "      <td>spring-projects/spring-framework</td>\n",
       "      <td>29816</td>\n",
       "      <td>bclozel</td>\n",
       "      <td>Commenter: bclozel\\nCreated At: 2023-01-13T17:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/spring-projects/spring-fram...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "a21fd566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.209625Z",
     "start_time": "2025-04-17T15:36:59.196985Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "06001f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.285464Z",
     "start_time": "2025-04-17T15:36:59.273784Z"
    }
   },
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=17, \n",
    "                                                  stratify=df.label.values)"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "0a3b84e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.427559Z",
     "start_time": "2025-04-17T15:36:59.413515Z"
    }
   },
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1171, 1086,  890, ..., 1495,  548,  928], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "36b37ba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.536959Z",
     "start_time": "2025-04-17T15:36:59.523424Z"
    }
   },
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "52bcb33d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.552662Z",
     "start_time": "2025-04-17T15:36:59.541967Z"
    }
   },
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "c36488d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.646941Z",
     "start_time": "2025-04-17T15:36:59.632941Z"
    }
   },
   "source": [
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        sl                           Project  pullNumber         author  \\\n",
       "0     9320     nightscout/cgm-remote-monitor        6288     jpcunningh   \n",
       "1     9321                      apache/spark       43881  dongjoon-hyun   \n",
       "2     9322                      apache/spark       43881  dongjoon-hyun   \n",
       "3     9323                      apache/spark       43881    LuciferYang   \n",
       "4     9324  spring-projects/spring-framework       29816        bclozel   \n",
       "...    ...                               ...         ...            ...   \n",
       "1598  8766                   grafana/grafana       16658        torkelo   \n",
       "1599  8767                   grafana/grafana       16658         Limess   \n",
       "1600  8768                   grafana/grafana       16658        dprokop   \n",
       "1601  8769                   grafana/grafana       16658        torkelo   \n",
       "1602  8770                   grafana/grafana       16658         Limess   \n",
       "\n",
       "                                                comment  \\\n",
       "0     Commenter: jpcunningh\\nCreated At: 2020-11-04T...   \n",
       "1     Commenter: dongjoon-hyun\\nCreated At: 2023-11-...   \n",
       "2     Commenter: dongjoon-hyun\\nCreated At: 2023-11-...   \n",
       "3     Commenter: LuciferYang\\nCreated At: 2023-11-20...   \n",
       "4     Commenter: bclozel\\nCreated At: 2023-01-13T17:...   \n",
       "...                                                 ...   \n",
       "1598  Commenter: torkelo\\nCreated At: 2019-05-16T19:...   \n",
       "1599  Commenter: Limess\\nCreated At: 2019-05-29T15:3...   \n",
       "1600  Commenter: dprokop\\nCreated At: 2019-06-25T07:...   \n",
       "1601  Commenter: torkelo\\nCreated At: 2019-04-24T13:...   \n",
       "1602  Commenter: Limess\\nCreated At: 2019-05-07T21:5...   \n",
       "\n",
       "                                                 path  Unnamed: 6  \\\n",
       "0                                                 NaN         NaN   \n",
       "1                                dev/infra/Dockerfile         NaN   \n",
       "2                                                 NaN         NaN   \n",
       "3                                                 NaN         NaN   \n",
       "4                                                 NaN         NaN   \n",
       "...                                               ...         ...   \n",
       "1598  public/app/core/components/PasswordStrength.tsx         NaN   \n",
       "1599  public/app/core/components/PasswordStrength.tsx         NaN   \n",
       "1600  public/app/core/components/PasswordStrength.tsx         NaN   \n",
       "1601                                              NaN         NaN   \n",
       "1602                                              NaN         NaN   \n",
       "\n",
       "                                                    URL  label data_type  \n",
       "0     https://github.com/nightscout/cgm-remote-monit...      1     train  \n",
       "1     https://github.com/apache/spark/pull/43881#dis...      1     train  \n",
       "2     https://github.com/apache/spark/pull/43881#iss...      1     train  \n",
       "3     https://github.com/apache/spark/pull/43881#iss...      1     train  \n",
       "4     https://github.com/spring-projects/spring-fram...      1     train  \n",
       "...                                                 ...    ...       ...  \n",
       "1598  https://github.com/grafana/grafana/pull/16658#...      1     train  \n",
       "1599  https://github.com/grafana/grafana/pull/16658#...      1     train  \n",
       "1600  https://github.com/grafana/grafana/pull/16658#...      1     train  \n",
       "1601  https://github.com/grafana/grafana/pull/16658#...      0     train  \n",
       "1602  https://github.com/grafana/grafana/pull/16658#...      1     train  \n",
       "\n",
       "[1603 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>URL</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9320</td>\n",
       "      <td>nightscout/cgm-remote-monitor</td>\n",
       "      <td>6288</td>\n",
       "      <td>jpcunningh</td>\n",
       "      <td>Commenter: jpcunningh\\nCreated At: 2020-11-04T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/nightscout/cgm-remote-monit...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9321</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>dongjoon-hyun</td>\n",
       "      <td>Commenter: dongjoon-hyun\\nCreated At: 2023-11-...</td>\n",
       "      <td>dev/infra/Dockerfile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9322</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>dongjoon-hyun</td>\n",
       "      <td>Commenter: dongjoon-hyun\\nCreated At: 2023-11-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#iss...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9323</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>43881</td>\n",
       "      <td>LuciferYang</td>\n",
       "      <td>Commenter: LuciferYang\\nCreated At: 2023-11-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/apache/spark/pull/43881#iss...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9324</td>\n",
       "      <td>spring-projects/spring-framework</td>\n",
       "      <td>29816</td>\n",
       "      <td>bclozel</td>\n",
       "      <td>Commenter: bclozel\\nCreated At: 2023-01-13T17:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/spring-projects/spring-fram...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>8766</td>\n",
       "      <td>grafana/grafana</td>\n",
       "      <td>16658</td>\n",
       "      <td>torkelo</td>\n",
       "      <td>Commenter: torkelo\\nCreated At: 2019-05-16T19:...</td>\n",
       "      <td>public/app/core/components/PasswordStrength.tsx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/grafana/grafana/pull/16658#...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>8767</td>\n",
       "      <td>grafana/grafana</td>\n",
       "      <td>16658</td>\n",
       "      <td>Limess</td>\n",
       "      <td>Commenter: Limess\\nCreated At: 2019-05-29T15:3...</td>\n",
       "      <td>public/app/core/components/PasswordStrength.tsx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/grafana/grafana/pull/16658#...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>8768</td>\n",
       "      <td>grafana/grafana</td>\n",
       "      <td>16658</td>\n",
       "      <td>dprokop</td>\n",
       "      <td>Commenter: dprokop\\nCreated At: 2019-06-25T07:...</td>\n",
       "      <td>public/app/core/components/PasswordStrength.tsx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/grafana/grafana/pull/16658#...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>8769</td>\n",
       "      <td>grafana/grafana</td>\n",
       "      <td>16658</td>\n",
       "      <td>torkelo</td>\n",
       "      <td>Commenter: torkelo\\nCreated At: 2019-04-24T13:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/grafana/grafana/pull/16658#...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>8770</td>\n",
       "      <td>grafana/grafana</td>\n",
       "      <td>16658</td>\n",
       "      <td>Limess</td>\n",
       "      <td>Commenter: Limess\\nCreated At: 2019-05-07T21:5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/grafana/grafana/pull/16658#...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1603 rows Ã— 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "5cbef260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.755690Z",
     "start_time": "2025-04-17T15:36:59.742514Z"
    }
   },
   "source": [
    "df.groupby(['label', 'label', 'data_type']).count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         sl  Project  pullNumber  author  comment  path  \\\n",
       "label label data_type                                                     \n",
       "0     0     train       304      304         304     304      304    48   \n",
       "            val          54       54          54      54       54     6   \n",
       "1     1     train      1058     1058        1058    1058     1058   621   \n",
       "            val         187      187         187     187      187    97   \n",
       "\n",
       "                       Unnamed: 6   URL  \n",
       "label label data_type                    \n",
       "0     0     train               0   304  \n",
       "            val                 0    54  \n",
       "1     1     train               0  1058  \n",
       "            val                 0   187  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "id": "f648da3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:36:59.895046Z",
     "start_time": "2025-04-17T15:36:59.882120Z"
    }
   },
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "c3385828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:00.338932Z",
     "start_time": "2025-04-17T15:37:00.219649Z"
    }
   },
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "id": "0e602c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:00.431116Z",
     "start_time": "2025-04-17T15:37:00.418505Z"
    }
   },
   "source": [
    "df[df.data_type=='train'].comment.values"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Commenter: jpcunningh\\nCreated At: 2020-11-04T04:45:10Z\\nUpdated At: 2020-11-04T04:45:10Z\\nAuthor Association: COLLABORATOR\\nHTML URL: https://github.com/nightscout/cgm-remote-monitor/pull/6288#issuecomment-721509093\\nComment (PR #6288)(PR Author: konstantinnightscoutheroku): \"Hi! This pull request was made in the wrong direction - this PR is trying to pull changes from your copy of Nightscout into the master version.  The correct direction is from master into your copy.  Don\\'t worry, no harm done!\\\\r\\\\n\\\\r\\\\nThe correct direction for your update PR can be created by this link: https://github.com/konstantinnightscoutheroku/cgm-remote-monitor/compare/master...nightscout:master\\\\r\\\\n\\\\r\\\\nWe\\'ll close this pull request, as it\\'s now in the Nightscout repository instead of the intended your personal copy.\"',\n",
       "       'Commenter: dongjoon-hyun\\nCreated At: 2023-11-18T05:33:45Z\\nUpdated At: 2023-11-18T05:33:45Z\\nAuthor Association: MEMBER\\nHTML URL: https://github.com/apache/spark/pull/43881#discussion_r1398094327\\nPath: dev/infra/Dockerfile\\nPatch: [@@ -79,11 +79,15 @@ RUN gpg --keyserver hkps://keyserver.ubuntu.com --recv-key E298A3A825C0D65DFD57C  RUN gpg -a --export E084DAB9 | apt-key add -  RUN add-apt-repository \\'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/\\'   -RUN Rscript -e \"install.packages(c(\\'knitr\\', \\'markdown\\', \\'rmarkdown\\', \\'testthat\\', \\'devtools\\', \\'e1071\\', \\'survival\\', \\'arrow\\', \\'roxygen2\\', \\'xml2\\'), repos=\\'https://cloud.r-project.org/\\')\" +RUN Rscript -e \"install.packages(c(\\'devtools\\', \\'knitr\\', \\'markdown\\',  \\\\ +    \\'rmarkdown\\', \\'testthat\\', \\'devtools\\', \\'e1071\\', \\'survival\\', \\'arrow\\',  \\\\ +    \\'ggplot2\\', \\'mvtnorm\\', \\'statmod\\', \\'xml2\\'), repos=\\'https://cloud.r-project.org/\\')\"    # See more in SPARK-39959, roxygen2 < 7.2.1 -RUN Rscript -e \"install.packages(c(\\'devtools\\'), repos=\\'https://cloud.r-project.org/\\')\"  RUN Rscript -e \"devtools::install_version(\\'roxygen2\\', version=\\'7.2.0\\', repos=\\'https://cloud.r-project.org\\')\" +RUN Rscript -e \"devtools::install_version(\\'lintr\\', version=\\'2.0.1\\', repos=\\'https://cloud.r-project.org\\')\" +RUN Rscript -e \"devtools::install_version(\\'pkgdown\\', version=\\'2.0.1\\', repos=\\'https://cloud.r-project.org\\')\" +RUN Rscript -e \"devtools::install_version(\\'preferably\\', version=\\'0.4\\', repos=\\'https://cloud.r-project.org\\')\"    # See more in SPARK-39735  ENV R_LIBS_SITE \"/usr/local/lib/R/site-library:${R_LIBS_SITE}:/usr/lib/R/library\"]\\nStart Line: None\\nOriginal Start Line: None\\nStart Side: None\\nLine: None\\nOriginal Line: 75\\nSide: LEFT\\nOriginal Position: 13\\nPosition: None\\nSubject Type: line\\nComment (PR #43881)(PR Author: zhengruifeng): \\'Or, shall you spin-off Python part because this PR title scope is `R package installation`, @zhengruifeng ?\\'',\n",
       "       \"Commenter: dongjoon-hyun\\nCreated At: 2023-11-20T04:05:01Z\\nUpdated At: 2023-11-20T04:05:01Z\\nAuthor Association: MEMBER\\nHTML URL: https://github.com/apache/spark/pull/43881#issuecomment-1818193617\\nComment (PR #43881)(PR Author: zhengruifeng): 'Merged to master.'\",\n",
       "       ...,\n",
       "       'Commenter: dprokop\\nCreated At: 2019-06-25T07:51:10Z\\nUpdated At: 2019-06-25T07:51:10Z\\nAuthor Association: MEMBER\\nHTML URL: https://github.com/grafana/grafana/pull/16658#discussion_r297050754\\nPath: public/app/core/components/PasswordStrength.tsx\\nPatch: [@@ -1,36 +1,64 @@ -import React from \\'react\\'; +import React, { PureComponent } from \\'react\\';    export interface Props {    password: string;  }   -export class PasswordStrength extends React.Component<Props, any> { +export interface State { +  getScore(password: string): number; +} + +export class PasswordStrength extends PureComponent<Props, State> {    constructor(props: Props) {      super(props); + +    this.state = { +      getScore(password: string) { +        if (password.length < 4) { +          return 1; +        } +        if (password.length < 8) { +          return 2; +        } +        return 3; +      }, +    }; +  } + +  componentDidMount() { +    import(/* webpackChunkName: \"zxcvbn\" */ \\'zxcvbn\\').then(zxcvbn => { +      this.setState({ +        getScore(password: string) { +          return zxcvbn.default(password).score; +        }, +      }); +    });    }      render() {      const { password } = this.props; -    let strengthText = \\'strength: strong like a bull.\\'; -    let strengthClass = \\'password-strength-good\\'; +    let strengthText = \\'strong like a bull.\\'; +    let strengthClassModifier = \\'good\\';        if (!password) {        return null;      }   -    if (password.length <= 8) { -      strengthText = \\'strength: you can do better.\\'; -      strengthClass = \\'password-strength-ok\\'; +    const passwordScore = this.state.getScore(password); + +    if (passwordScore <= 2) { +      strengthText = \\'you can do better.\\'; +      strengthClassModifier = \\'ok\\';      }   -    if (password.length < 4) { -      strengthText = \\'strength: weak sauce.\\'; -      strengthClass = \\'password-strength-bad\\'; +    if (passwordScore <= 1) { +      strengthText = \\'weak sauce.\\'; +      strengthClassModifier = \\'bad\\';      }        return ( -      <div className={`password-strength small ${strengthClass}`}> -        <em>{strengthText}</em> +      <div className={`password-strength small password-strength-${strengthClassModifier}`}> +        <em>strength: {strengthText}</em>        </div>      );    }]\\nStart Line: None\\nOriginal Start Line: None\\nStart Side: None\\nLine: 16\\nOriginal Line: 16\\nSide: RIGHT\\nOriginal Position: 15\\nPosition: 18\\nSubject Type: line\\nComment (PR #16658)(PR Author: Lusitaniae): \"I haven\\'t seen this approach being used neither. Not sure what the benefit of having this method in state is compared to regular instance method, bu this feels flaky. I see this being driven only by the dynamic import in `componentDidMount`. For that I suggest creating a higher order component that would serve as module loader and deliver the loaded module or part of its API to the desired component (PasswordStrength in this case)\"',\n",
       "       \"Commenter: torkelo\\nCreated At: 2019-04-24T13:14:40Z\\nUpdated At: 2019-04-24T13:14:40Z\\nAuthor Association: MEMBER\\nHTML URL: https://github.com/grafana/grafana/pull/16658#issuecomment-486223882\\nComment (PR #16658)(PR Author: Lusitaniae): 'Thanks for contributing, we will try to review and merge this soon'\",\n",
       "       'Commenter: Limess\\nCreated At: 2019-05-07T21:58:54Z\\nUpdated At: 2019-05-07T22:47:05Z\\nAuthor Association: CONTRIBUTOR\\nHTML URL: https://github.com/grafana/grafana/pull/16658#issuecomment-490270494\\nComment (PR #16658)(PR Author: Lusitaniae): \"It\\'s worth noting that `zxcvbn.js` is a huge `400kB` gzipped. I\\'d highly recommend lazy loading this when used or loading it asynchronously on only the registration pages.\\\\r\\\\n\\\\r\\\\nI\\'ve raised https://github.com/Lusitaniae/grafana/pull/1/ to this branch if you\\'re interested in lazy loading `zxcvn` using webpack.\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "0df3d667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:00.462835Z",
     "start_time": "2025-04-17T15:37:00.452621Z"
    }
   },
   "source": [
    "df.iloc[X_val[0]]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl                                                         8356\n",
       "Project                                         pytorch/pytorch\n",
       "pullNumber                                                 5182\n",
       "author                                                  apaszke\n",
       "comment       Commenter: apaszke\\nCreated At: 2018-03-01T13:...\n",
       "path                                   test/test_distributed.py\n",
       "Unnamed: 6                                                  NaN\n",
       "URL           https://github.com/pytorch/pytorch/pull/5182#d...\n",
       "label                                                         1\n",
       "data_type                                                   val\n",
       "Name: 1244, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "276489e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:00.600297Z",
     "start_time": "2025-04-17T15:37:00.587908Z"
    }
   },
   "source": [
    "df.iloc[y_val[0]]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl                                                         9321\n",
       "Project                                            apache/spark\n",
       "pullNumber                                                43881\n",
       "author                                            dongjoon-hyun\n",
       "comment       Commenter: dongjoon-hyun\\nCreated At: 2023-11-...\n",
       "path                                       dev/infra/Dockerfile\n",
       "Unnamed: 6                                                  NaN\n",
       "URL           https://github.com/apache/spark/pull/43881#dis...\n",
       "label                                                         1\n",
       "data_type                                                 train\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "6ed3df50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:00.753065Z",
     "start_time": "2025-04-17T15:37:00.740920Z"
    }
   },
   "source": [
    "X_val[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1244"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "id": "87735a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:00.954968Z",
     "start_time": "2025-04-17T15:37:00.943270Z"
    }
   },
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# # Replace 'model_name' with the name of the pre-trained model you're using\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Assuming you have a DataFrame named 'df'\n",
    "# for index, row in df.iterrows():\n",
    "#     data_type = row['data_type']\n",
    "#     message = row['comment']\n",
    "#     label = row['label']\n",
    "\n",
    "#     encoded_data = tokenizer.encode_plus(\n",
    "#         text=message,\n",
    "#         add_special_tokens=True,\n",
    "#         return_attention_mask=True,\n",
    "#         pad_to_max_length=True,\n",
    "#         max_length=256,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "\n",
    "#     input_ids = encoded_data['input_ids']\n",
    "#     attention_mask = encoded_data['attention_mask']\n",
    "    \n",
    "#     print(f\"Processing row {index + 1} - Data Type: {data_type}, Message: {message}, Label: {label}\")\n",
    "    \n",
    "#     # Here you can proceed with storing or processing 'input_ids', 'attention_mask', and 'label'\n",
    " "
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "00940b72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.185029Z",
     "start_time": "2025-04-17T15:37:01.111186Z"
    }
   },
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].comment.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].comment.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\huisu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "8ccf04ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.200471Z",
     "start_time": "2025-04-17T15:37:11.190200Z"
    }
   },
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "b499bb90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.261375Z",
     "start_time": "2025-04-17T15:37:11.247334Z"
    }
   },
   "source": [
    "len(dataset_train)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1362"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "id": "ccff5eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.324077Z",
     "start_time": "2025-04-17T15:37:11.311433Z"
    }
   },
   "source": [
    "len(dataset_val)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "id": "7b4ab05b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.617522Z",
     "start_time": "2025-04-17T15:37:11.434332Z"
    }
   },
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "id": "68bfc532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.648308Z",
     "start_time": "2025-04-17T15:37:11.639425Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "id": "3d6fd2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.771453Z",
     "start_time": "2025-04-17T15:37:11.758240Z"
    }
   },
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "id": "339c8430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.787253Z",
     "start_time": "2025-04-17T15:37:11.776935Z"
    }
   },
   "source": [
    "from transformers import get_linear_schedule_with_warmup"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "id": "d0c94701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.849281Z",
     "start_time": "2025-04-17T15:37:11.836288Z"
    }
   },
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "id": "01f3ddf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.911747Z",
     "start_time": "2025-04-17T15:37:11.898133Z"
    }
   },
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "id": "a3d4ee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:11.958368Z",
     "start_time": "2025-04-17T15:37:11.944176Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "id": "87f127f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:12.019969Z",
     "start_time": "2025-04-17T15:37:12.006025Z"
    }
   },
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "id": "1f0bfc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:12.066881Z",
     "start_time": "2025-04-17T15:37:12.052383Z"
    }
   },
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "id": "63ac8eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:12.129022Z",
     "start_time": "2025-04-17T15:37:12.115021Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "id": "dfe92cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:12.874384Z",
     "start_time": "2025-04-17T15:37:12.192445Z"
    }
   },
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:12.936773Z",
     "start_time": "2025-04-17T15:37:12.923792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n"
   ],
   "id": "d1fdd92331427d4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "12.1\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "id": "c8835969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:37:12.999815Z",
     "start_time": "2025-04-17T15:37:12.986609Z"
    }
   },
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "id": "db5b24ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:47:50.061272Z",
     "start_time": "2025-04-17T15:37:13.064019Z"
    }
   },
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)             \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5283f6edb51e45abbab6410ece383438"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/86 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8115e5780e2a4b64839dd26c0b1330d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.4381205348601175\n",
      "Validation loss: 0.3817555597051978\n",
      "F1 Score (Weighted): 0.8446609358891702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2:   0%|          | 0/86 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0c1642bb13e4ff88145f58d07289640"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.3138299656295499\n",
      "Validation loss: 0.2715671982150525\n",
      "F1 Score (Weighted): 0.9044272568959215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3:   0%|          | 0/86 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8c0f558d21648f38d9539da772d69b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.267019537515765\n",
      "Validation loss: 0.3145741396583617\n",
      "F1 Score (Weighted): 0.8828126571319885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4:   0%|          | 0/86 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5355b82a14c14fff9aa08062fdae2c08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.23464250373978948\n",
      "Validation loss: 0.2788805556483567\n",
      "F1 Score (Weighted): 0.9092981751661982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5:   0%|          | 0/86 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce220848644843739f0b225b7a96f370"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.20629362640685814\n",
      "Validation loss: 0.26069540344178677\n",
      "F1 Score (Weighted): 0.9087136929460581\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "id": "b362e82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:47:58.085961Z",
     "start_time": "2025-04-17T15:47:50.219223Z"
    }
   },
   "source": [
    "val_loss, predictions, true_vals = evaluate(dataloader_validation)"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "id": "a955e3f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:47:58.102060Z",
     "start_time": "2025-04-17T15:47:58.090980Z"
    }
   },
   "source": [
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "id": "d6729845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:47:59.321944Z",
     "start_time": "2025-04-17T15:47:58.166035Z"
    }
   },
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "id": "81149d75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:47:59.678883Z",
     "start_time": "2025-04-17T15:47:59.401665Z"
    }
   },
   "source": [
    "# model.load_state_dict(torch.load('finetuned_BERT_MYDATA.model', map_location=torch.device('cpu')))\n",
    "model.load_state_dict(torch.load('finetuned_BERT_epoch_5.model', map_location=torch.device('cpu')))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huisu\\AppData\\Local\\Temp\\ipykernel_1296\\144352875.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('finetuned_BERT_epoch_5.model', map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "id": "49ca89b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:07.638511Z",
     "start_time": "2025-04-17T15:47:59.760417Z"
    }
   },
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "id": "2471037e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:07.716054Z",
     "start_time": "2025-04-17T15:48:07.703077Z"
    }
   },
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Accuracy: 43/54\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 176/187\n",
      "\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "id": "ed27f7e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:07.809726Z",
     "start_time": "2025-04-17T15:48:07.795726Z"
    }
   },
   "source": [
    "len(predictions), len(true_vals)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 241)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "id": "4dd7ca82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:07.901900Z",
     "start_time": "2025-04-17T15:48:07.888456Z"
    }
   },
   "source": [
    "from sklearn import metrics"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "id": "60dff5b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:07.982772Z",
     "start_time": "2025-04-17T15:48:07.968921Z"
    }
   },
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(preds_flat, true_vals))\n",
    "print(\"Precision:\",metrics.precision_score(preds_flat, true_vals))\n",
    "print(\"Recall:\",metrics.recall_score(preds_flat, true_vals))\n",
    "print(\"f1 score\", metrics.f1_score(preds_flat, true_vals, average='weighted'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9087136929460581\n",
      "Precision: 0.9411764705882353\n",
      "Recall: 0.9411764705882353\n",
      "f1 score 0.9087136929460581\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "id": "c58dfad4",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "id": "9096a859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.278349Z",
     "start_time": "2025-04-17T15:48:08.064141Z"
    }
   },
   "source": [
    "xlsx_file ='test_bert_author.xlsx'\n",
    "df_test = pd.read_excel(xlsx_file)\n",
    "#df_test = pd.read_csv(xlsx_file)\n",
    "df_test.head()"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_bert_author.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[119], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m xlsx_file \u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_bert_author.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 2\u001B[0m df_test \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxlsx_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#df_test = pd.read_csv(xlsx_file)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m df_test\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001B[0m, in \u001B[0;36mread_excel\u001B[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n\u001B[0;32m    503\u001B[0m     should_close \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 504\u001B[0m     io \u001B[38;5;241m=\u001B[39m \u001B[43mExcelFile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine \u001B[38;5;241m!=\u001B[39m io\u001B[38;5;241m.\u001B[39mengine:\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    512\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    513\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    514\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001B[0m, in \u001B[0;36mExcelFile.__init__\u001B[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxls\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1563\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[43minspect_excel_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontent_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\n\u001B[0;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1566\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1567\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1568\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExcel file format cannot be determined, you must specify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1569\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man engine manually.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1570\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001B[0m, in \u001B[0;36minspect_excel_format\u001B[1;34m(content_or_path, storage_options)\u001B[0m\n\u001B[0;32m   1416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content_or_path, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m   1417\u001B[0m     content_or_path \u001B[38;5;241m=\u001B[39m BytesIO(content_or_path)\n\u001B[1;32m-> 1419\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcontent_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1421\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[0;32m   1422\u001B[0m     stream \u001B[38;5;241m=\u001B[39m handle\u001B[38;5;241m.\u001B[39mhandle\n\u001B[0;32m   1423\u001B[0m     stream\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:872\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    864\u001B[0m             handle,\n\u001B[0;32m    865\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    868\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    869\u001B[0m         )\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    873\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'test_bert_author.xlsx'"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "id": "6c6a4bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.302211900Z",
     "start_time": "2025-02-24T19:08:39.019912Z"
    }
   },
   "source": [
    "possible_labels = df_test.actual.unique()\n",
    "possible_labels"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "e0a27dae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.304214800Z",
     "start_time": "2025-02-24T19:08:40.518869Z"
    }
   },
   "source": [
    "label_dict = {0: 0, 1: 1}\n",
    "label_dict"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "0d5e2c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.304214800Z",
     "start_time": "2025-02-24T19:08:41.975065Z"
    }
   },
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "f1f6a6c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.307387Z",
     "start_time": "2025-02-24T19:08:43.273424Z"
    }
   },
   "source": [
    "df_test['label'] = df_test.actual.replace(label_dict)"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "9b05905e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.308386900Z",
     "start_time": "2025-02-24T19:08:44.928181Z"
    }
   },
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# # Replace 'model_name' with the name of the pre-trained model you're using\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# df_test = df_test[10000:]\n",
    "\n",
    "# # Assuming you have a DataFrame named 'df'\n",
    "# for index, row in df_test.iterrows():\n",
    "#     #data_type = row['data_type']\n",
    "#     message = row['comment']\n",
    "#     label = row['actual']\n",
    "\n",
    "#     encoded_data = tokenizer.encode_plus(\n",
    "#         text=message,\n",
    "#         add_special_tokens=True,\n",
    "#         return_attention_mask=True,\n",
    "#         pad_to_max_length=True,\n",
    "#         max_length=256,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "\n",
    "#     input_ids = encoded_data['input_ids']\n",
    "#     attention_mask = encoded_data['attention_mask']\n",
    "    \n",
    "#     print(f\"Processing row {index + 1}, Message: {message}, Label: {label}\")\n",
    "    \n",
    "#     # Here you can proceed with storing or processing 'input_ids', 'attention_mask', and 'label'\n",
    " "
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "f147843b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.308386900Z",
     "start_time": "2025-02-24T19:08:47.327010Z"
    }
   },
   "source": [
    "# encoded_test_val = tokenizer.batch_encode_plus(\n",
    "#     df_test.comment.values, \n",
    "#     add_special_tokens=True, \n",
    "#     return_attention_mask=True, \n",
    "#     pad_to_max_length=True, \n",
    "#     max_length=256, \n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "encoded_test_val = tokenizer.batch_encode_plus(\n",
    "    df_test.comment.values.tolist(),  # Convert NumPy array to list\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huisu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "649f32a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.308386900Z",
     "start_time": "2025-02-24T19:09:05.984614Z"
    }
   },
   "source": [
    "input_ids_test = encoded_test_val['input_ids']\n",
    "attention_masks_test = encoded_test_val['attention_mask']\n",
    "labels_test = torch.tensor(df_test.label.values)"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "0e22eabf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.309388500Z",
     "start_time": "2025-02-24T19:09:08.213919Z"
    }
   },
   "source": [
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test,labels_test)\n",
    "batch_size = 8\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), \n",
    "                                   batch_size=batch_size)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "b5c181b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.309388500Z",
     "start_time": "2025-02-24T19:09:09.800400Z"
    }
   },
   "source": [
    "def test_model(dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':         batch[2],\n",
    "                }  \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "a38ecc60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.309388500Z",
     "start_time": "2025-02-24T19:09:12.902060Z"
    }
   },
   "source": [
    "pred_test = test_model(dataloader_test) \n",
    "preds_flat_test = np.argmax(pred_test, axis=1).flatten()\n",
    "print(preds_flat_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "1a3699da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.309388500Z",
     "start_time": "2025-02-24T19:18:26.101060Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "pred_data = pd.DataFrame(preds_flat_test, columns = [\"prediction\"])\n",
    "pd_cont = pd.concat([df_test[\"comment\"], pred_data], axis = 1)\n",
    "pd_cont.to_csv(\"test_bert_author_prediction.csv\")"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "c98ec1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.310389600Z",
     "start_time": "2025-02-24T19:18:28.572375Z"
    }
   },
   "source": [
    "len(pred_data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16501"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "0c3667e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.310389600Z",
     "start_time": "2025-02-24T19:18:30.472765Z"
    }
   },
   "source": [
    "len(X_val)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "2790ae22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.310389600Z",
     "start_time": "2025-02-24T19:18:59.523382Z"
    }
   },
   "source": [
    "pred_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       prediction\n",
       "0               0\n",
       "1               0\n",
       "2               0\n",
       "3               0\n",
       "4               0\n",
       "...           ...\n",
       "16496           0\n",
       "16497           0\n",
       "16498           0\n",
       "16499           0\n",
       "16500           1\n",
       "\n",
       "[16501 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16497</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16500</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16501 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "b0eb8ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.311391200Z",
     "start_time": "2025-02-24T19:19:01.855657Z"
    }
   },
   "source": [
    "df_slice = df_test[\"message\"]\n",
    "df_slice.reset_index()"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'message'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3789\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3790\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3791\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'message'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_slice \u001B[38;5;241m=\u001B[39m \u001B[43mdf_test\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessage\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      2\u001B[0m df_slice\u001B[38;5;241m.\u001B[39mreset_index()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3793\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3794\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3795\u001B[0m     ):\n\u001B[0;32m   3796\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3797\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3798\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3799\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3801\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'message'"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "9e1bf974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:48:08.312387700Z",
     "start_time": "2025-02-24T19:18:51.558614Z"
    }
   },
   "source": [
    "pd_cont_rst = pd.concat([df_slice.reset_index(), pred_data], axis = 1)\n",
    "pd_cont_rst.to_csv(\"done.csv\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[71], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pd_cont_rst \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([\u001B[43mdf_slice\u001B[49m\u001B[38;5;241m.\u001B[39mreset_index(), pred_data], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      2\u001B[0m pd_cont_rst\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_slice' is not defined"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be0a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
